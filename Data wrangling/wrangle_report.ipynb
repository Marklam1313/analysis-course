{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the wrangling part, before I handle all the issues, I have made a copy for each dataframe, so I could wrangle the copies instead. \n",
    "\n",
    "I have identified the following quality and tidiness issues:\n",
    "\n",
    "For quality issues:\n",
    "\n",
    "For issue #1, I realised the columns timestamp and retweeted_status_timestamp are in object (string) type, but they should be in datetime type. So I have used .to_datetime to convert the data into datetime64 type. \n",
    "\n",
    "For issue #2, tweet_id from all three dataframes should be in str type, so I have used .astype(str) to convert the columns into object (string).\n",
    "\n",
    "For issue #3, I realised that some tweets from df_archive are retweets, which might be duplicates of older tweets, or even irrelevant tweets that don't provide a rating for any dog. So I have used identified retweets with retweeted_status_id != 'NaN', and drop those rows.\n",
    "\n",
    "For issue #4, in df_archive, after removing tweets that are retweets, the columns \"retweeted_status_id\", \"retweeted_status_user_id\" and \"retweeted_status_timestamp\" don't provide any useful information. So I have dropped these columns.\n",
    "\n",
    "For issue #5, in df_archive, some rating denominators are not 10, which might be caused by reading the wrong denominators from the tweet. This will make any analysis unfair. So I have identified the rows with denominators not equal to 10, and dropped these rows.\n",
    "\n",
    "For issue #6, in df_public, some rows don't contain any useful information, as they have 'NaN' for either columns, or even all 4 columns. So I have dropped these rows, and test by seeing if there's any row with 'NaN' value.\n",
    "\n",
    "For issue #7, in df_public, the columns 'retweet_count', 'reply_count', 'like_count', 'quote_count' are in float types instead of int type, so I have used .astype(int) to convert them into int type.\n",
    "\n",
    "For issue #8, in df_archive, out of 2153 entries, the columns of 'in_reply_to_status_id' and 'in_reply_to_user_id' consists of 2080 rows of \"NaN\", which means only 3% of the data from the columns provide some limited information. So we believe they should be removed.\n",
    "\n",
    "\n",
    "For tidiness issues:\n",
    "\n",
    "For issue #1, since we always want each variable forms a column, each observation forms a row, each type of observational unit forms a table, I merged three data frames together, as they share the same 'tweet_id' column. By merging them on 'tweet_id', we have a master dataframe.\n",
    "\n",
    "For issue #2, since the columns \"doggo\", \"floofer\", \"pupper\", and \"puppo\" are referring to the same information - which word has been mentioned in the tweet, they should be grouped into one column - \"mentioned\". I did that by melt method, and also creating a function that identifies 'none' in all 4 columns, so we could keep these rows afterwards when we tried to drop duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
